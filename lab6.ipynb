{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import lxml.html as l\n",
    "import json\n",
    "\n",
    "def extract_data(path):\n",
    "    source = open(path).read()\n",
    "    root = l.fromstring(source)\n",
    "    beatmapset = root.xpath(\".//script[@id='json-beatmapset']/text()\")\n",
    "    if len(beatmapset) == 0: return None\n",
    "    beatmapset = beatmapset[0]\n",
    "    return json.loads(beatmapset)\n",
    "\n",
    "download_dir = '../parser-vmedv/beatmapsets'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T12:23:46.194093Z",
     "start_time": "2024-03-05T12:23:46.187526Z"
    }
   },
   "id": "998565f43f1d9656",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "\n",
    "genres = {}\n",
    "\n",
    "for root, directories, files in os.walk(download_dir):\n",
    "    for file in files:\n",
    "        beatmapset = extract_data(download_dir + os.sep + file)\n",
    "        if beatmapset is None:\n",
    "            continue\n",
    "        img_covers = beatmapset['covers']\n",
    "        if img_covers is None: \n",
    "            continue\n",
    "        img_url = img_covers['cover']\n",
    "        if img_url is None:\n",
    "            continue\n",
    "            \n",
    "        # print(json.dumps(beatmapset, indent=4))\n",
    "        # break\n",
    "        if genres.__contains__(beatmapset['genre']['name']):\n",
    "            genres[beatmapset['genre']['name']] += 1\n",
    "        else:\n",
    "            genres[beatmapset['genre']['name']] = 1\n",
    " \n",
    "        id = img_url[img_url.find(\"beatmaps\") + 9 : img_url.find(\"covers\") - 1]\n",
    "        pic = Path(f'pictures/{id}.jpg')\n",
    "        pref = \"\"\n",
    "        if beatmapset['genre']['name'] == 'Electronic':\n",
    "            pref = 'electronic'\n",
    "        else:\n",
    "            pref = 'non-electronic'\n",
    "        if pic.is_file():\n",
    "            os.replace(pic, f\"pictures/{pref}/{id}.jpg\")\n",
    "            continue\n",
    "        pic = Path(f'pictures/{pref}/{id}.jpg')\n",
    "        if pic.is_file():\n",
    "            continue\n",
    "        img_data = requests.get(img_url).content\n",
    "        with open(f'pictures/{pref}/{img_url[img_url.find(\"beatmaps\") + 9 : img_url.find(\"covers\") - 1]}.jpg', 'wb') as handler:\n",
    "            handler.write(img_data)\n",
    "        try:\n",
    "            img = cv2.imread(f'pictures/{pref}/{img_url[img_url.find(\"beatmaps\") + 9 : img_url.find(\"covers\") - 1]}.jpg')\n",
    "        except:\n",
    "            print(\"error message\")\n",
    "            pass \n",
    "print(genres)\n"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T19:33:39.105102Z",
     "start_time": "2024-03-05T19:33:39.101703Z"
    }
   },
   "id": "150e08c664de6512",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "def check_Image(path):\n",
    "    try:\n",
    "        _ = Image.open(path)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "data = torchvision.datasets.ImageFolder(root='./pictures/', transform=transforms.ToTensor(), is_valid_file=check_Image)\n",
    "train, test = torch.utils.data.random_split(data, [0.8, 0.2])\n",
    "dataloaders = {\n",
    "    'train': DataLoader(\n",
    "        dataset=train,\n",
    "        batch_size=64,\n",
    "        shuffle=True\n",
    "    ),\n",
    "    'val': DataLoader(\n",
    "        dataset=test,\n",
    "        batch_size=64,\n",
    "        shuffle=False\n",
    "    )\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T00:54:30.977467Z",
     "start_time": "2024-03-06T00:54:30.082374Z"
    }
   },
   "id": "4972922ca275c32c",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class OsuGenreClassifier(nn.Module):\n",
    "    def __init__(self, ouput_dim):\n",
    "        super(OsuGenreClassifier, self).__init__()\n",
    "        self.model = resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(1000, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(64, ouput_dim)\n",
    "        )\n",
    "\n",
    "    def embed(self, x):\n",
    "        return self.fc1(self.model(x))\n",
    "\n",
    "    def forward(self, x):\n",
    "        resnet_out = self.embed(x)\n",
    "        return self.fc2(resnet_out)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T00:55:39.368327Z",
     "start_time": "2024-03-06T00:55:39.360933Z"
    }
   },
   "id": "12c2f40bb37f18b4",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Epoch: 1. Phase: train:   0%|          | 0/125 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12aafcf01f3c476485b4323bf9d91bfd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5854 Acc: 0.7098 F1_score: 0.8248956356736243"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch: 1. Phase: val:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "49647c651b2b45498344e8814e348539"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.5536 Acc: 0.7302 F1_score: 0.8379988088147707"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch: 2. Phase: train:   0%|          | 0/125 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "331673bff0a14d5f86e77d3062ab7985"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5608 Acc: 0.7188 F1_score: 0.831798278725653"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch: 2. Phase: val:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "463252a7b7e2475d859ae15b3e92f903"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.5479 Acc: 0.7267 F1_score: 0.8345932869670396"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch: 3. Phase: train:   0%|          | 0/125 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ce9c2df3f954f1599c88d15566f5758"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5515 Acc: 0.7258 F1_score: 0.8342499236174763"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch: 3. Phase: val:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dcf295aaa375418ca9ea3c941d812aa8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.5434 Acc: 0.7297 F1_score: 0.8350983358547656"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch: 4. Phase: train:   0%|          | 0/125 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d394c02e61bc4b0ba79dd2d40809c637"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5466 Acc: 0.7299 F1_score: 0.8354643595436797"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch: 4. Phase: val:   0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af039aeb31d2487887f364f087862d78"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.5416 Acc: 0.7340 F1_score: 0.8344741754822651"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "model = OsuGenreClassifier(2)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), amsgrad=True, lr=1e-4)\n",
    "\n",
    "for epoch in range(4):\n",
    "\n",
    "    for phase in ['train', 'val']:\n",
    "        dataloader = dataloaders[phase]\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        elif phase == 'val':\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "\n",
    "        pred = []\n",
    "        target = []\n",
    "        for (X_batch, y_batch) in tqdm(dataloader, desc=f'Epoch: {epoch + 1}. Phase: {phase}'):\n",
    "            X_batch = X_batch / 255\n",
    "            X_batch = transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(X_batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                y_pred = model(X_batch)\n",
    "\n",
    "                loss_value = loss_function(y_pred, y_batch)\n",
    "                y_pred_class = y_pred.argmax(dim=1)\n",
    "\n",
    "                pred.append(y_pred_class)\n",
    "                target.append(y_batch)\n",
    "                if phase == 'train':\n",
    "                    loss_value.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss_value.item()\n",
    "            running_acc += (y_pred_class == y_batch.data).float().mean().data.cpu().numpy()\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader)\n",
    "        epoch_acc = running_acc / len(dataloader)\n",
    "\n",
    "        t1 = torch.stack(pred[0:-1])\n",
    "        t2 = torch.stack(target[0:-1])\n",
    "        \n",
    "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} F1_score: {f1_score(t1.data, t2.data, average=\"micro\")}', end='')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T04:52:38.107247Z",
     "start_time": "2024-03-06T00:55:41.637970Z"
    }
   },
   "id": "ec1db14422b338ff",
   "execution_count": 55
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
